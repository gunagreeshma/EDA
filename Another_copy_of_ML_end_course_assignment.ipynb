{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "nqoHp30x9hH9",
        "-Kee-DAl2viO",
        "gIfDvo9L0UH2"
      ],
      "cell_execution_strategy": "setup",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gunagreeshma/EDA/blob/main/Another_copy_of_ML_end_course_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    -\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Classification\n",
        "##### **Contribution**    - Individual\n",
        "\n",
        "Health Insurance Cross Sell Prediction"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Write the summary here within 500-600 words.\n",
        "\n",
        "The task at hand involves assisting an insurance company, specializing in health coverage, to extend its services by predicting the interest of policyholders in obtaining vehicle insurance. This predictive model is crucial for the company's strategic planning, enabling targeted communication efforts and optimization of the overall business model and revenue streams. In the insurance realm, policyholders pay a regular premium to the company in exchange for a guarantee of compensation in case of specified loss, damage, illness, or death. This payment-sharing mechanism spreads the risk among a pool of customers. For instance, in health insurance, a customer might pay an annual premium of Rs. 5000 for coverage up to Rs. 200,000. The company can afford such potential high costs because, statistically, only a fraction of the insured customers will actually require significant payouts in a given year.\n",
        "\n",
        "Now, the company aims to diversify its offerings to include vehicle insurance, necessitating a predictive model to discern which customers from the previous year might express interest in this new coverage. The dataset for this project includes diverse information such as demographics (gender, age, region code type), details about vehicles (vehicle age, damage status), and policy-related information (premium amount, sourcing channel). Leveraging this data, the predictive model will discern patterns and relationships to identify the likelihood of a customer opting for vehicle insurance.\n",
        "\n",
        "Key variables such as gender, age, and region code type will be scrutinized to understand their influence on customer behavior. Insights into the condition of vehicles, considering factors like vehicle age and damage status, will provide valuable indicators. Additionally, policy-specific details, including premium amounts and the sourcing channel, will be integral in gauging customer interest. The model aims to draw correlations between these variables and the likelihood of customers seeking vehicle insurance.\n",
        "\n",
        "Ultimately, the successful development and implementation of this predictive model will empower the insurance company to tailor its communication strategy effectively. By proactively reaching out to customers with a higher likelihood of interest in vehicle insurance, the company can enhance its customer engagement, optimize resource allocation, and maximize revenue potential in this new business segment. This data-driven approach aligns with contemporary business practices, ensuring strategic decisions are grounded in empirical insights for sustainable growth and competitive advantage.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Write Problem Statement Here.**\n",
        "\n",
        "Our client is an Insurance company that has provided Health Insurance to its customers now they need your help in building a model to predict whether the policyholders (customers) from past year will also be interested in Vehicle Insurance provided by the company. An insurance policy is an arrangement by which a company undertakes to provide a guarantee of compensation for specified loss, damage, illness, or death in return for the payment of a specified premium. A premium is a sum of money that the customer needs to pay regularly to an insurance company for this guarantee. For example, you may pay a premium of Rs. 5000 each year for a health insurance cover of Rs. 200,000/- so that if, God forbid, you fall ill and need to be hospitalised in that year, the insurance provider company will bear the cost of hospitalisation etc. for upto Rs. 200,000. Now if you are wondering how can company bear such high hospitalisation cost when it charges a premium of only Rs. 5000/-, that is where the concept of probabilities comes in picture. For example, like you, there may be 100 customers who would be paying a premium of Rs. 5000 every year, but only a few of them (say 2-3) would get hospitalised that year and not everyone. This way everyone shares the risk of everyone else.\n",
        "Just like medical insurance, there is vehicle insurance where every year customer needs to pay a premium of certain amount to insurance provider company so that in case of unfortunate accident by the vehicle, the insurance provider company will provide a compensation (called ‘sum assured’) to the customer.\n",
        "Building a model to predict whether a customer would be interested in Vehicle Insurance is extremely helpful for the company because it can then accordingly plan its communication strategy to reach out to those customers and optimise its business model and revenue.\n",
        "Now, in order to predict, whether the customer would be interested in Vehicle insurance, you have information about demographics (gender, age, region code type), Vehicles (Vehicle Age, Damage), Policy (Premium, sourcing channel) etc.\n"
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pandas #install the pandas library"
      ],
      "metadata": {
        "id": "hVkaTGTcodIq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Libraries\n",
        "import pandas as pd #Pandas allows for quick exploration of data.\n",
        "import numpy as np #useful for performing operations on entire columns or rows of a dataset without the need for explicit loops.\n"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "QVIh7wDLPaYx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "filepath= \"/content/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv\"\n",
        "dataset=pd.read_csv(filepath) # Reads a comma-separated values (CSV) file into a DataFrame."
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "dataset"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "# Get the number of rows and columns using the 'shape' attribute\n",
        "count_rows, count_columns = dataset.shape\n",
        "\n",
        "# Print the number of rows\n",
        "print(f\"Number of rows: {count_rows}\")\n",
        "\n",
        "# Print the number of columns\n",
        "print(f\"Number of columns: {count_columns}\")"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "# Display information about the dataset\n",
        "dataset.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the first 5 rows and all columns of the dataset\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "icAKRl_MuzTA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Display the last 5 rows and all columns of the dataset\n",
        "dataset.tail()"
      ],
      "metadata": {
        "id": "kAvthlxxtp9O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the shape of the dataset (number of rows and columns)\n",
        "dataset_shape = dataset.shape\n",
        "print(f\"Dataset shape: {dataset_shape}\")\n"
      ],
      "metadata": {
        "id": "3KLhUXC5tp5s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "# Count the number of duplicate rows in the dataset\n",
        "duplicate_count = dataset.duplicated().sum()\n",
        "print(f\"Number of duplicate rows in the dataset: {duplicate_count}\")\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "missing_values_count = dataset.isnull().sum()\n",
        "print(\"Missing values count in each column:\")\n",
        "print(missing_values_count)\n"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create a heatmap to visualize missing values\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.heatmap(dataset.isnull(), cbar=False, cmap='viridis')\n",
        "plt.title('Visualization of Missing Values')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Represents the lowest values or the minimum value in the dataset, and in the context of missing values, it indicates the absence of missing values.\n",
        "So, a full purple color in the heatmap suggests that there are no missing values in the dataset. This is a good sign as it means that  dataset is complete in terms of available data for each column."
      ],
      "metadata": {
        "id": "jNKkVQVOxjTT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No Duplicate Values:\n",
        "\n",
        "The dataset does not contain any duplicate values. You may have checked for duplicates and found that there are none.\n",
        "No Missing Values:\n",
        "\n",
        "There are no missing values in the dataset. You confirmed this by visualizing the missing values using a heatmap and observing a full purple color.\n",
        "Number of Rows and Columns:\n",
        "\n",
        "The dataset has a total of 131802 rows and 12 columns. This information was obtained using the shape attribute, which returns a tuple representing the dimensions of the dataset.\n",
        "In summary, your dataset appears to be clean, without duplicate or missing values, and it has a considerable number of rows and columns. This is a good starting point for further analysis or modeling."
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "dataset.columns # Display the column names of the dataset"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "dataset.describe() # Display descriptive statistics of the dataset"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "id : Unique ID for the customer\n",
        "\n",
        "Gender : Gender of the customer\n",
        "\n",
        "Age : Age of the customer\n",
        "\n",
        "Driving_License 0 : Customer does not have DL, 1 : Customer already has DL\n",
        "\n",
        "Region_Code : Unique code for the region of the customer\n",
        "\n",
        "Previously_Insured : 1 : Customer already has Vehicle Insurance, 0 : Customer doesn't have Vehicle Insurance\n",
        "\n",
        "Vehicle_Age : Age of the Vehicle\n",
        "\n",
        "Vehicle_Damage :1 : Customer got his/her vehicle damaged in the past. 0 : Customer didn't get his/her vehicle damaged in the past.\n",
        "\n",
        "Annual_Premium : The amount customer needs to pay as premium in the year\n",
        "\n",
        "PolicySalesChannel : Anonymized Code for the channel of outreaching to the customer ie. Different Agents, Over Mail, Over Phone, In Person, etc.\n",
        "\n",
        "Vintage : Number of Days, Customer has been associated with the company\n",
        "\n",
        "Response : 1 : Customer is interested, 0 : Customer is not interested\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TybNOGTA4kBT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Unique Values for each variable.\n",
        "for column in dataset.columns:\n",
        "    unique_values = dataset[column].unique()\n",
        "    print(f\"Unique values for {column}:\\n{unique_values}\\n\") # Check unique values for each variable (column)\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Write your code to make your dataset analysis ready.\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Define numerical columns for outlier treatment\n",
        "numerical_columns = ['Age', 'Annual_Premium', 'Vintage']\n",
        "\n",
        "# Create box plots to visualize outliers\n",
        "plt.figure(figsize=(15, 6))\n",
        "plt.subplots_adjust(wspace=0.5)\n",
        "\n",
        "for i, column in enumerate(numerical_columns, 1):\n",
        "    plt.subplot(1, len(numerical_columns), i)\n",
        "    sns.boxplot(x=dataset[column])\n",
        "    plt.title(f'Box Plot of {column}')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Outlier treatment using Z-score\n",
        "for column in numerical_columns:\n",
        "    # Calculate Z-scores for each value in the column\n",
        "    z_scores = np.abs((dataset[column] - dataset[column].mean()) / dataset[column].std())\n",
        "\n",
        "    # Set a threshold for Z-scores (e.g., 3) to identify outliers\n",
        "    threshold = 3\n",
        "\n",
        "    # Replace outliers with NaN\n",
        "    dataset[column] = np.where(z_scores > threshold, np.nan, dataset[column])\n",
        "\n",
        "# Optional: Impute NaN values with a strategy of your choice\n",
        "dataset = dataset.dropna()  # Drop rows with NaN values, or use another imputation strategy\n",
        "\n",
        "# Display updated dataset information\n",
        "print(\"Updated Dataset Information:\")\n",
        "print(dataset.info())\n"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Define the column for outlier treatment\n",
        "column_name = 'Annual_Premium'\n",
        "\n",
        "# Create a box plot before removing outliers\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.boxplot(x=dataset[column_name])\n",
        "plt.title(f'Box Plot of {column_name} (Before Outlier Removal)')\n",
        "plt.show()\n",
        "\n",
        "# Calculate IQR for 'Annual_Premium'\n",
        "Q1 = dataset[column_name].quantile(0.25)\n",
        "Q3 = dataset[column_name].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Set a threshold to identify outliers\n",
        "threshold = 1.5\n",
        "\n",
        "# Remove rows with outliers in 'Annual_Premium' using IQR method\n",
        "dataset = dataset[~((dataset[column_name] < (Q1 - threshold * IQR)) | (dataset[column_name] > (Q3 + threshold * IQR)))]\n",
        "\n",
        "# Create a box plot after removing outliers\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.boxplot(x=dataset[column_name])\n",
        "plt.title(f'Box Plot of {column_name} (After Outlier Removal)')\n",
        "plt.show()\n",
        "\n",
        "# Display updated dataset information\n",
        "print(\"Updated Dataset Information:\")\n",
        "print(dataset.info())\n"
      ],
      "metadata": {
        "id": "pW5eoJ2Yy4eI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "**Data Exploration**:\n",
        "\n",
        "Checked for duplicate values in the dataset.\n",
        "Checked for missing values in the dataset.\n",
        "Displayed information about the dataset using the info() method.\n",
        "Displayed the first and last few rows of the dataset using the head() and tail() methods.\n",
        "Checked unique values for each variable using the unique() method.\n",
        "\n",
        "**Outlier Treatment**:\n",
        "Visualized outliers using box plots.\n",
        "Identified and treated outliers in numerical columns using Z-scores.\n",
        "Removed outliers using the Z-score method and displayed box plots before and after the removal.\n",
        "\n",
        "**Specifics for 'Annual_Premium' Column**:\n",
        "\n",
        "Displayed a box plot for the 'Annual_Premium' column.\n",
        "Identified outliers in the 'Annual_Premium' column using Z-scores.\n",
        "Removed outliers from the 'Annual_Premium' column using the Z-score method.\n",
        "Displayed a side-by-side comparison of the box plot for 'Annual_Premium' before and after removing outliers.\n",
        "\n",
        "**Dataset Information:**\n",
        "\n",
        "Displayed the shape of the dataset (number of rows and columns).\n",
        "Displayed descriptive statistics of the dataset using the describe() method.\n",
        "Displayed information about the dataset after each manipulation.\n"
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 1 visualization code\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.countplot(x='Gender', data=dataset)\n",
        "plt.title('Count of Customers by Gender')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a countplot, specifically used for visualizing the distribution of categorical variables. In this case, it is employed to display the count of customers based on their gender. The countplot is suitable for visualizing the frequency or distribution of categories within a single categorical variable."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight from the chart is that there are more male customers than female customers. This conclusion is drawn by comparing the heights of the bars representing the counts of each gender category."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Will the gained insights help create a positive business impact?\n",
        "\n",
        "The provided information alone doesn't necessarily indicate whether it will have a positive or negative impact on the business. However, knowing the gender distribution can be valuable for targeted marketing, product development, or customer engagement strategies. For example, if the business wants to launch a product that is more appealing to a specific gender, this insight can help in tailoring marketing campaigns to target the predominant gender group"
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Are there any insights that lead to negative growth? Justify with a specific reason.\n",
        "\n",
        "The chart itself doesn't provide insights into negative growth. However, if the business heavily relies on a gender-specific market, and the predominant gender group is not aligning with the business objectives, it could potentially impact growth negatively. For instance, if the business is introducing products mainly designed for females, but the majority of customers are males, it might result in lower sales and market acceptance for those products. It emphasizes the importance of aligning products and strategies with the demographics of the customer base.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "fWQR00EBlq1T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 2 visualization code\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(dataset['Age'], bins=20, kde=True)\n",
        "plt.title('Distribution of Customer Ages')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The histogram with KDE is a suitable choice for visualizing the distribution of a continuous variable, such as age. It provides insights into the central tendency, spread, and shape of the data. The combination of bars (histogram) and the smooth line (KDE) helps to capture both the discrete distribution and the underlying continuous probability density function"
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a higher frequency of customers in the age range of 20 to 30, as indicated by the taller bars in that range.\n",
        "The KDE line forming a bell curve suggests a relatively normal distribution of ages, with a peak around the mean age."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "positive business impact\n",
        "Valuable insights can guide targeted marketing, informed product development, and tailored customer engagement strategies, leading to increased customer satisfaction and loyalty.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "A highly concentrated age distribution may pose a risk. If the predominant age group undergoes significant changes in preferences or if there's a demographic shift, the business may face challenges. Diversifying the customer base is crucial to mitigate potential negative impacts on growth.\n"
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 3"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 3 visualization code\n",
        "plt.figure(figsize=(10, 4))\n",
        "sns.countplot(x='Vehicle_Age', data=dataset)\n",
        "plt.title('Count of Vehicles by Age')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a count plot depicting the distribution of vehicles based on their age. A count plot is suitable for visualizing the frequency of categorical data, making it a good choice for understanding the distribution of vehicle ages."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The highest count is observed in the  1-2 years category, indicating that a significant portion of the vehicles falls within this age range.\n",
        "The second-highest count is in the <1 year category, suggesting a substantial number of recently acquired vehicles.\n",
        "The <2 years category appears to have fewer vehicles compared to the '1-2 years' and <1 year categories."
      ],
      "metadata": {
        "id": "lNPuLjeK5Ek6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Positive Impact:\n",
        "\n",
        "The insights can help the business tailor its services or marketing strategies based on the age distribution of vehicles.\n",
        "For example, if there's a high concentration of vehicles in the '1-2 years' category, the business might focus on services relevant to newer vehicles, such as warranty extensions, maintenance packages, or promotions for the latest models.\n",
        "\n",
        "Negative Growth Insights:\n",
        "\n",
        "While the count plot itself doesn't indicate negative growth, a potential concern could arise if there's a decline in the '<1 year' category. This might suggest a decrease in the acquisition of new vehicles, which could impact the business's revenue from new sales or related services.Here"
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 4"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 4 visualization code\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.histplot(dataset['Annual_Premium'], bins=20, kde=True)\n",
        "plt.title('Distribution of Annual Premiums')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " A histogram with a kernel density estimate (KDE) for the 'Annual_Premium' variable in the dataset using Seaborn. This type of chart is chosen to visualize the distribution of annual premiums, providing insights into the central tendency, spread, and shape of the data."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "There is a prominent bar with the highest frequency in the 'Annual_Premium' range between 0 to 10000.\n",
        "The KDE line suggests a decreasing trend in frequencies as the 'Annual_Premium' values increase, with a notable drop around 60000."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Understanding the distribution of annual premiums can guide pricing strategies, helping the business set competitive rates within the prevalent range of 0 to 10000. This insight can contribute to attracting more customers and improving customer satisfaction.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "The drop in frequency around 60000 could indicate a potential issue. If this is a significant premium category, the business might face challenges if there's a lack of customers in this range. It's important to investigate why there's a decline and whether it reflects customer dissatisfaction, a pricing problem, or other factors that could negatively impact growth in that premium category. Further analysis and understanding customer behavior in this range are crucial to address and mitigate potential negative impacts on business growth.\n"
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 5"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Distribution of Previously Insured Customers')\n",
        "\n",
        "# Assuming 0 represents 'Not Previously Insured' and 1 represents 'Previously Insured'\n",
        "labels = ['Not Previously Insured', 'Previously Insured']\n",
        "\n",
        "# Assuming dataset['Previously_Insured'] contains binary values (0 or 1)\n",
        "counts = dataset['Previously_Insured'].value_counts()\n",
        "\n",
        "# Plotting a pie chart with labels\n",
        "plt.pie(counts, labels=labels, autopct='%1.1f%%', startangle=90, colors=['blue', 'orange'])\n",
        "\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "8EsP0iU6mG3z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a pie chart. Pie charts are effective for displaying the distribution of categories as parts of a whole. In this case, it's used to visualize the proportion of previously insured and not previously insured customers in the dataset."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Previously insured customers constitute 46.0% of the total, and not previously insured customers constitute 54.0%."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Understanding the distribution of previously insured and not previously insured customers can aid in tailoring marketing strategies, product offerings, and customer engagement approaches. This insight can contribute to customer satisfaction and loyalty.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If there's an imbalance in the distribution, it could potentially lead to negative growth. For example, if a large portion of customers is already insured, there might be limited growth opportunities in acquiring new customers. Conversely, if a majority is not insured, there could be challenges related to revenue and profitability. Balancing the customer base and strategizing accordingly is essential for sustained growth."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 6"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 6 visualization code\n",
        "plt.figure(figsize=(8, 4))\n",
        "sns.boxplot(x='Response', y='Vintage', data=dataset)\n",
        "plt.title('Vintage Distribution by Response')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a boxplot. Boxplots are effective for visualizing the distribution of a numerical variable across different categories, making it suitable for comparing the distribution of 'Vintage' for different response categories ('Response' 0 and 1)."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The box plot compares the distribution of 'Vintage' for two response categories, 0 and 1.\n",
        "The absence of variance in the box plot may suggest that there is little difference in the distribution of 'Vintage' between the two response categories."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact\n",
        "\n",
        "Understanding the distribution of 'Vintage' for different response categories can provide insights into customer behavior. This information can be valuable for refining marketing strategies, customer engagement, and product offerings to better cater to the characteristics of customers in each response category.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If there is no significant difference in the distribution of 'Vintage' between the two response categories, it may be challenging to tailor strategies specifically for each category. This lack of distinction in customer behavior might limit the effectiveness of targeted approaches, potentially leading to missed opportunities for positive business impact. It's important to explore other variables and factors that may contribute to a more meaningful segmentation for business strategies.\n",
        "\n"
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 7"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 7 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Assuming 'Region_Code' is a categorical variable\n",
        "plt.figure(figsize=(15, 6))\n",
        "sns.countplot(x='Region_Code', data=dataset, order=dataset['Region_Code'].value_counts().index)\n",
        "plt.title('Count of Customers by Region Code')\n",
        "plt.xlabel('Region Code')\n",
        "plt.ylabel('Count')\n",
        "plt.xticks(rotation=45)\n",
        "plt.show()\n",
        "\n"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a countplot. Countplots are particularly useful for visualizing the distribution of categorical variables by displaying the count of observations in each category."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The insight is that for the 'Region_Code' 28.0, the count is 100,000."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insight can be valuable for business decisions. For example, if 'Region_Code' 28.0 is significant for the business, knowing that there are 100,000 customers associated with it can guide resource allocation, marketing strategies, and customer engagement efforts specifically tailored to that region.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If the count for 'Region_Code' 28.0 is unusually high and not in line with expectations or business goals, it could be a cause for concern. This might indicate a data anomaly, potential errors, or bias in the dataset. Inaccurate information could lead to misguided business decisions and negatively impact growth. It's important to validate the data quality and ensure that the observed pattern is reflective of the actual customer distribution in that region."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 8"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Vehicle_Damage', data=dataset)\n",
        "plt.title('Count of Vehicles by Damage Status')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a countplot. Countplots are effective for visualizing the distribution of categorical variables by displaying the count of observations in each category. In this case, it's used to show the count of vehicles based on their damage status ('Yes' or 'No')."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The count of vehicles with damage ('Yes') is higher than the count of vehicles without damage ('No')."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insight that there are more damaged vehicles can be valuable for business decisions. It can inform insurance pricing, claims processing, and customer communication strategies. Understanding the prevalence of damaged vehicles allows the business to tailor its services and offerings to better address the needs of customers with damaged vehicles.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If the count of damaged vehicles is unexpectedly high and not in line with industry standards or internal expectations, it could lead to concerns about product quality, safety issues, or an increase in accidents. Negative perceptions about vehicle safety may result in decreased customer trust, potentially impacting business growth. It's crucial to investigate the reasons behind the high count of damaged vehicles and take corrective actions if needed to maintain positive growth.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Driving_License', data=dataset)\n",
        "plt.title('Count of Customers by Driving License Status')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The selected chart is a countplot. Countplots are effective for visualizing the distribution of categorical variables by displaying the count of observations in each category. In this case, it's used to show the count of customers based on their driving license status (1 for \"Yes\" and 0 for \"No\")."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The count of customers with a driving license ('1') is higher than the count of customers without a driving license ('0')."
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insight that there are more customers with driving licenses can be valuable for various business decisions. It may influence marketing strategies, product offerings, and customer engagement approaches. Understanding the driving license status of customers allows the business to tailor its services to better suit the needs of customers with driving licenses.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If the count of customers without a driving license is unexpectedly high, it might impact certain business aspects. For example, if the business heavily relies on customers with driving licenses for a particular service or product, an unexpectedly low count in this category could lead to a negative growth concern. Understanding the reasons behind the distribution and adjusting business strategies accordingly is crucial for maintaining positive growth."
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 visualization code\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Driving_License', hue='Gender', data=dataset)\n",
        "plt.title('Distribution of Driving Licenses by Gender')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a grouped countplot with hue. This type of chart is effective for visualizing the distribution of a categorical variable (in this case, 'Driving_License') across multiple categories (in this case, 'Gender')."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For customers with a driving license ('1'), the bar for males is higher than the bar for females.\n",
        "For customers without a driving license ('0'), there is a slight difference in the bar heights between males and females."
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insight that there is a gender difference in the distribution of driving licenses can be valuable for business decisions. It might influence targeted marketing strategies, product offerings, and customer engagement approaches. Understanding how driving licenses are distributed among different genders allows the business to tailor its services to better suit the preferences and needs of specific customer segments.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If the business heavily relies on customers with driving licenses and there is a significant gender disparity in obtaining driving licenses, it could potentially impact certain business aspects. For example, if the business primarily targets a market segment that is less likely to have a driving license, it might limit the growth potential for services or products that require driving. Understanding and addressing such disparities can be crucial for maintaining positive growth."
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 11"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 11 visualization codes\n",
        "# Create a bar plot for  'Response'\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.countplot(x='Response', data=dataset)\n",
        "plt.title('Bar plot for Response')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a violin plot. Violin plots are effective for visualizing the distribution of a numerical variable across different categories, providing insights into the shape, spread, and concentration of the data."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The violin plot shows that for 'Response' 0, the lower probability region is elongated, suggesting potential variability or concentration in certain age ranges for customers who did not respond positively.\n",
        "\n",
        "In contrast, for 'Response' 1, the violin plot is not as elongated, indicating a more consistent distribution of age for customers who responded positively.\n",
        "\n",
        "These insights can be valuable for understanding the age distribution patterns among customers who responded positively and negatively. The elongation in the lower probability region for 'Response' 0 might imply that certain age groups are less likely to respond positively, and this information can guide targeted marketing strategies and customer engagement efforts. It's essential for businesses to tailor their approaches based on such insights to enhance positive outcomes and growth."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, the insights gained from the violin plot can be valuable for business decisions. Understanding the distribution of response for different categories can inform marketing strategies, product development, and customer engagement. It allows the business to tailor its approaches based on the characteristics of customers who responded positively or negatively.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If the distribution for 'Response' 0 shows unexpected variation or concentration  it may raise concerns.\n"
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 12"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 12 visualization code\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create a DataFrame for plotting\n",
        "pie_data = dataset.groupby(['Previously_Insured', 'Gender']).size().unstack()\n",
        "\n",
        "# Plot the pie chart for 'Previously Insured' category\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Distribution of Previously Insured Customers by Gender')\n",
        "\n",
        "# Extract the data for the 'Previously Insured' category\n",
        "previously_insured_data = pie_data.loc[1]\n",
        "\n",
        "plt.pie(previously_insured_data, labels=previously_insured_data.index, autopct='%1.1f%%', startangle=90, wedgeprops=dict(width=0.3), pctdistance=0.85)\n",
        "\n",
        "# Draw a circle in the center to make it a donut chart\n",
        "centre_circle = plt.Circle((0, 0), 0.6, color='white', edgecolor='black', linewidth=0.8)\n",
        "fig = plt.gcf()\n",
        "fig.gca().add_artist(centre_circle)\n",
        "\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a donut chart. Donut charts are variations of pie charts, and in this case, they are used to represent the distribution of previously insured customers by gender. The donut chart includes percentages, making it easy to compare the distribution of categories."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chart shows the distribution of previously insured customers by gender.\n",
        "The female percentile is 50.5%, and the male percentile is 49.5%."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insight that there is a nearly equal distribution of previously insured customers between genders can be valuable for business decisions. This information can influence marketing strategies, product offerings, and customer engagement approaches. The business can tailor its services to suit the needs and preferences of both genders, contributing to positive customer experiences.\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If there were a significant imbalance in the distribution between genders, it might raise concerns. For example, if the business heavily relies on one gender for previously insured customers and neglects the other, it could limit the growth potential. A skewed distribution might indicate a missed opportunity to cater to a broader audience. Therefore, a nearly equal distribution, as observed in this case, is generally positive for growth and customer inclusivity.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 13"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 13 visualization code\n",
        "\n",
        "# Create a pie chart for the distribution of vehicle ages\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Assuming 'Vehicle_Age' is a categorical variable with values like '1-2 Year', '< 1 Year', '>= 2 Years'\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.title('Distribution of Vehicle Ages')\n",
        "dataset['Vehicle_Age'].value_counts().plot.pie(autopct='%1.1f%%', labels=dataset['Vehicle_Age'].value_counts().index, startangle=90)\n",
        "plt.ylabel('')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "sfcf4ls1EdMk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a pie chart. Pie charts are effective for showing the proportional distribution of categories within a dataset. In this case, it is used to represent the distribution of vehicle ages."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Less than 1 year: 43.6%\n",
        "1-2 years: 52.4%\n",
        "Greater than 2 years: 4.0%"
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Positive Business Impact:\n",
        "\n",
        "Yes, the insights gained from the pie chart can be valuable for business decisions. Understanding the distribution of vehicle ages allows the business to tailor its services, marketing, and product offerings to different segments. For instance, if there's a high percentage of vehicles with an age of 1-2 years, the business may focus on services and promotions relevant to that specific group\n",
        "\n",
        "Negative Growth Concern:\n",
        "\n",
        "If there were a significant imbalance in the distribution of vehicle ages and the business failed to recognize it, it could lead to missed opportunities. For example, if the business primarily focuses on services for vehicles less than 1 year old but there is a substantial market for older vehicles, it might limit growth potential. It's important for businesses to adapt their strategies based on the actual distribution of their customer base to avoid overlooking potential markets.\n"
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "\n",
        "correlation_matrix = dataset.corr()\n",
        "\n",
        "# Plot a heatmap to visualize correlations\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
        "plt.title('Correlation Heatmap')\n",
        "plt.show()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The specific chart chosen is a correlation heatmap. This type of chart is particularly effective for visually representing the correlation structure between different variables in a dataset. The heatmap uses color to quickly convey the strength and direction of correlations, making it easy to identify relationships and patterns in the data.\n",
        "\n",
        "Heatmaps are especially useful when dealing with correlation matrices, providing an intuitive way to assess the degree of linear relationship between variables. The choice of this chart allows for a comprehensive and visually appealing exploration of the inter-variable correlations in the dataset."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The values along the diagonal (from the top left to the bottom right) represent the correlation of each variable with itself, and they are always 1.00. These are shown in red to highlight the perfect correlation.\n",
        "\n",
        "The off-diagonal cells represent the correlation between pairs of variables. The color indicates the strength and direction of the correlation:\n",
        "\n",
        "Dark red indicates a strong positive correlation.\n",
        "Dark blue indicates a strong negative correlation.\n",
        "Light colors (closer to white) indicate weaker correlations.\n",
        "In summary, the red diagonal in the heatmap represents the perfect correlation of each variable with itself, which is expected (correlation of a variable with itself is always 1.00). The off-diagonal cells show the correlations between different pairs of variables in the dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Selecting specific columns for the pair plot\n",
        "selected_columns = ['Age', 'Annual_Premium', 'Vintage', 'Response']\n",
        "\n",
        "# Create a pair plot for the selected columns\n",
        "sns.pairplot(dataset[selected_columns], hue='Response', diag_kind='kde')\n",
        "plt.suptitle('Pair Plot of Selected Numerical Variables', y=1.02)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "CLv-8M_X0-DZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The chosen chart is a pair plot. A pair plot is particularly useful when you want to visualize the relationships between multiple numerical variables in a dataset simultaneously. It provides scatterplots for each pair of variables, histograms along the diagonal, and allows for the incorporation of hue (color) to differentiate between different levels of a categorical variable (in this case, 'Response').\n",
        "\n",
        "Pair plots are effective for identifying patterns, trends, and potential relationships between variables, making them a valuable exploratory data analysis tool. The inclusion of kernel density estimates (kde) on the diagonal adds a smoothed representation of the univariate distribution for each variable. This specific chart facilitates a comprehensive visual examination of the selected numerical variables and their interactions with the target variable ('Response')"
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " observed in a scatter plot that points with a response of 0 are more concentrated in a specific region and points with a response of 1 are less concentrated or scattered, it could suggest a potential correlation or separation between the two response categories concerning the plotted variables."
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1: The average age of customers who responded positively (Response=1) is significantly different from the average age of customers who responded negatively (Response=0).\n",
        "\n",
        "Statement 2: There is a significant difference in annual premiums between customers with different vehicle ages.\n",
        "\n",
        "Statement 3: The response to the insurance offer (Response) is independent of the gender of the customer."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 1: The average age of customers who responded positively (Response=1) is significantly different from the average age of customers who responded negatively (Response=0).\n",
        "\n",
        "Null Hypothesis (H0): The average age of customers with a positive response is equal to the average age of customers with a negative response.\n",
        "\n",
        "Alternative Hypothesis (H1): The average age of customers with a positive response is different from the average age of customers with a negative response."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import ttest_ind\n",
        "\n",
        "# Extract data for customers with positive and negative responses\n",
        "positive_response_age = dataset['Age'][dataset['Response'] == 1]\n",
        "negative_response_age = dataset['Age'][dataset['Response'] == 0]\n",
        "\n",
        "# Perform two-sample t-test\n",
        "t_statistic, p_value = ttest_ind(positive_response_age, negative_response_age, equal_var=False)\n",
        "\n",
        "# Print the results\n",
        "print(f'Two-sample t-test t-statistic: {t_statistic:.4f}')\n",
        "print(f'P-value: {p_value:.4f}')\n",
        "\n",
        "# Check significance\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The average age of customers with positive response is significantly different from the average age of customers with negative response.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The average age of customers with positive response is equal to the average age of customers with negative response.\")\n"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the p-value is less than 0.05, it have  enough evidence to reject the null hypothesis. Therefore, it can conclude that the average age of customers with a positive response is significantly different from the average age of customers with a negative response."
      ],
      "metadata": {
        "id": "3JZlFqhiAZ-F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I have performed a two-sample t-test to compare the means of age for customers with positive and negative responses.\n"
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The two-sample t-test is appropriate for comparing the means of two independent groups. The objective is to compare the means of two independent groups (ages of customers with positive and negative responses).\n",
        "The data involves continuous numerical variables (age).\n",
        "We are comparing the means of two groups to determine if they are statistically significantly different."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 2: There is a significant difference in annual premiums between customers with different vehicle ages.\n",
        "\n",
        "Null Hypothesis (H0): There is no significant difference in annual premiums between customers with different vehicle ages.\n",
        "\n",
        "Alternative Hypothesis (H1): There is a significant difference in annual premiums between customers with different vehicle ages."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import f_oneway\n",
        "\n",
        "# Extract data for different vehicle age groups\n",
        "vehicle_age_groups = dataset['Vehicle_Age'].unique()\n",
        "grouped_data = [dataset['Annual_Premium'][dataset['Vehicle_Age'] == age_group] for age_group in vehicle_age_groups]\n",
        "\n",
        "# Perform ANOVA test\n",
        "f_statistic, p_value = f_oneway(*grouped_data)\n",
        "\n",
        "# Print the results\n",
        "print(f'ANOVA F-statistic: {f_statistic:.4f}')\n",
        "print(f'P-value: {p_value:.4f}')\n",
        "\n",
        "# Check significance\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: There is a significant difference in annual premiums between customers with different vehicle ages.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: There is no significant difference in annual premiums between customers with different vehicle ages.\")\n",
        "\n"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I mentioned that the statistical test used to obtain the p-value is the Analysis of Variance (ANOVA) test. Specifically, the f_oneway function from the scipy.stats module was used to perform the ANOVA test."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The p-value is very close to zero (P-value: 0.0000), which is less than the significance level (alpha = 0.05).\n",
        "Therefore,  reject the null hypothesis.\n",
        "\n",
        "ANOVA is used when comparing means among three or more groups.\n",
        "In this case, we are comparing the means of annual premiums across different vehicle age groups.\n",
        "The rejection of the null hypothesis suggests that there is evidence to support the claim that there is a significant difference in annual premiums between customers with different vehicle ages"
      ],
      "metadata": {
        "id": "q5_bpQoPB7rx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Statement 3: The response to the insurance offer (Response) is independent of the gender of the customer.\n",
        "\n",
        "Null Hypothesis (H0): The response to the insurance offer is independent of the gender of the customer.\n",
        "\n",
        "\n",
        "Alternative Hypothesis (H1): The response to the insurance offer is dependent on the gender of the customer."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(dataset['Response'], dataset['Gender'])\n",
        "\n",
        "# Perform chi-square test\n",
        "chi2_stat, p_value, _, _ = chi2_contingency(contingency_table)\n",
        "\n",
        "# Print the results\n",
        "print(f'Chi-square statistic: {chi2_stat:.4f}')\n",
        "print(f'P-value: {p_value:.4f}')\n",
        "\n",
        "# Check significance\n",
        "alpha = 0.05\n",
        "if p_value < alpha:\n",
        "    print(\"Reject the null hypothesis: The response to the insurance offer is dependent on the gender of the customer.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis: The response to the insurance offer is independent of the gender of the customer.\")\n"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The p-value is very close to zero (P-value: 0.0000), which is less than the significance level (alpha = 0.05).\n",
        "Therefore, reject the null hypothesis."
      ],
      "metadata": {
        "id": "pikS9dTJCygN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The statistical test used to obtain the p-value in these test  is the Chi-square test for independence. The chi2_contingency function from the scipy.stats module was used to perform this test."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Chi-square test for independence is appropriate when examining the association between two categorical variables.\n",
        "In this case, we are testing if there is a significant association between the response to the insurance offer and the gender of the customer.\n",
        "The rejection of the null hypothesis suggests that there is evidence to support the claim that the response to the insurance offer is dependent on the gender of the customer."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "missing_values_count = dataset.isnull().sum()\n",
        "print(\"Missing values count in each column:\")\n",
        "print(missing_values_count)\n",
        "\n"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This code calculates and prints the count of missing values in each column of the 'dataset', providing information about the extent of missing data in the dataset."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# Assuming your dataset is named 'dataset', replace it with your actual variable name\n",
        "# Example: dataset = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "# Define the column for outlier treatment\n",
        "column_name = 'Annual_Premium'\n",
        "\n",
        "# Create a box plot before removing outliers\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.boxplot(x=dataset[column_name])\n",
        "plt.title(f'Box Plot of {column_name} (Before Outlier Removal)')\n",
        "plt.show()\n",
        "\n",
        "# Calculate IQR for 'Annual_Premium'\n",
        "Q1 = dataset[column_name].quantile(0.25)\n",
        "Q3 = dataset[column_name].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "# Set a threshold to identify outliers\n",
        "threshold = 1.5\n",
        "\n",
        "# Remove rows with outliers in 'Annual_Premium' using IQR method\n",
        "dataset = dataset[~((dataset[column_name] < (Q1 - threshold * IQR)) | (dataset[column_name] > (Q3 + threshold * IQR)))]\n",
        "\n",
        "# Create a box plot after removing outliers\n",
        "plt.figure(figsize=(6, 6))\n",
        "sns.boxplot(x=dataset[column_name])\n",
        "plt.title(f'Box Plot of {column_name} (After Outlier Removal)')\n",
        "plt.show()\n",
        "\n",
        "# Display updated dataset information\n",
        "print(\"Updated Dataset Information:\")\n",
        "print(dataset.info())\n"
      ],
      "metadata": {
        "id": "0mqWdoZE38OZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " the IQR (Interquartile Range) method for outlier treatment. This technique is employed to identify and remove outliers from the 'Annual_Premium' column. The IQR method is chosen for its robustness against extreme values and its ability to provide a balanced approach to outlier removal based on the distribution of the data. It helps maintain data integrity while addressing potential skewness or extreme values in the 'Annual_Premium' column"
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "gLOfm8oCMQqq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encode your categorical columns\n",
        "dataset['Gender'] = dataset['Gender'].map({'Female':1, 'Male':0})\n",
        "dataset.head()\n"
      ],
      "metadata": {
        "id": "D0m9F7lUOCts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Vehicle_Age']= dataset['Vehicle_Age'].map({'< 1 Year':0,'1-2 Year':1,'> 2 Years':2})\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "x8CE50vFOU2_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['Vehicle_Damage']=dataset['Vehicle_Damage'].map({'Yes':1, 'No':0})\n",
        "dataset.head()"
      ],
      "metadata": {
        "id": "0R3qTS6BOUYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Label Encoding is suitable for ordinal categorical variables where there is a clear order or ranking among the categories.\n",
        "It is particularly useful when the categorical values have a meaningful numeric representation or when building models that require numerical input."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "EAkbYdW6ken1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on the provided information, the columns with the 'object' data type are potentially textual. In your dataset, these columns are 'Gender', 'Vehicle_Age', and 'Vehicle_Damage'. However, having an 'object' data type does not necessarily mean that the column contains textual data. It could also include categorical data or other non-numeric types."
      ],
      "metadata": {
        "id": "-rt0nFNKw5Fv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Expand Contraction"
      ],
      "metadata": {
        "id": "O8fMAnvSw99W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations\n",
        "\n"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords\n",
        "\n"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Rephrase Text\n",
        "\n"
      ],
      "metadata": {
        "id": "Ajw6R9c0u6D4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)\n"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#  this line calculates the correlation matrix for all numeric columns in the dataset.\n",
        "correlation = dataset.corr()\n",
        "\n",
        "# The correlation matrix is a square matrix where each cell represents the correlation coefficient between two variables.\n",
        "# In this case, it seems like the code is interested in the correlation with the 'Response' variable.\n",
        "\n",
        "# This line extracts the correlation values between 'Response' and all other variables, sorts them in descending order,\n",
        "# and excludes the 'Response' itself (hence [1:] to exclude the first element, which is 'Response').\n",
        "correlation_with_response = correlation['Response'].sort_values(ascending=False)[1:]\n",
        "\n",
        "# The result is a pandas Series containing correlation coefficients for each variable in the dataset\n",
        "# in descending order of their correlation with the 'Response' variable.\n"
      ],
      "metadata": {
        "id": "sC8GYllGQmX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.info()"
      ],
      "metadata": {
        "id": "8BqyZO2uzQ-Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking the shape of dataset\n",
        "dataset.shape"
      ],
      "metadata": {
        "id": "1pNq7P1q3L9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features\n",
        "X=dataset.drop(columns=['id','Driving_License','Policy_Sales_Channel','Vintage','Response'])# independent variable\n",
        "y = dataset['Response']# dependent variable\n"
      ],
      "metadata": {
        "id": "W2T3j__aWt5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Fill any numerical NaNs with mode()\n",
        "fill_mode = lambda col: col.fillna(col.mode())\n",
        "X = X.apply(fill_mode, axis=0)\n",
        "dataset = dataset.apply(fill_mode, axis=0)\n"
      ],
      "metadata": {
        "id": "xyAutuQKW4Ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Examining the correlation between features and the target variable to identify relationships. This is done in the code using correlation['Response'].sort_values(ascending=False)[1:]"
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For Feature Selection, applied the Mutual Information technique. Here we observed that response is the most important feature and has the highest impact on the dependent feature"
      ],
      "metadata": {
        "id": "lx9A_QYkLOGe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?\n",
        "\n"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# List of numerical columns to scale\n",
        "numerical_columns = ['Age', 'Annual_Premium', 'Vintage']\n",
        "\n",
        "# Initialize the StandardScaler\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Apply scaling to the specified columns\n",
        "dataset[numerical_columns] = scaler.fit_transform(dataset[numerical_columns])\n",
        "\n",
        "# Display the updated dataset information\n",
        "print(\"Updated Dataset Information after Scaling:\")\n",
        "print(dataset.info())\n"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I have used the StandardScaler method from the sklearn.preprocessing module to scale  data. The StandardScaler method standardizes the features by removing the mean and scaling to unit variance.\n",
        "\n",
        " Mean Removal:\n",
        "\n",
        "StandardScaler subtracts the mean of the feature from each data point. This ensures that the scaled data has a mean of 0, which can be beneficial for certain algorithms that assume zero-centered data.\n",
        "Unit Variance:\n",
        "\n",
        "It scales the data to have a unit variance. This is important because it ensures that all features are on a similar scale, preventing features with larger variances from dominating the learning process."
      ],
      "metadata": {
        "id": "4M7NWWvBh0tz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " Dimensionality reduction can significantly enhance computational efficiency, especially when dealing with large datasets. By reducing the number of features, the training and prediction times of machine learning models can be substantially decreased."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "\n",
        "\n",
        "# Select numerical and categorical columns\n",
        "numerical_columns = ['Age', 'Driving_License', 'Region_Code', 'Previously_Insured',\n",
        "                     'Annual_Premium', 'Policy_Sales_Channel', 'Vintage']\n",
        "\n",
        "categorical_columns = ['Vehicle_Damage']\n",
        "\n",
        "# Separate features and target variable\n",
        "X = dataset.drop(['Response'], axis=1)\n",
        "y = dataset['Response']\n",
        "\n",
        "# Create a ColumnTransformer to apply transformations to numerical and categorical columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numerical_columns),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_columns)\n",
        "    ]\n",
        ")\n",
        "\n",
        "# Fit and transform the data\n",
        "X_transformed = preprocessor.fit_transform(X)\n",
        "\n",
        "# Apply PCA\n",
        "pca = PCA(n_components=0.95)  # explained variance threshold\n",
        "pca_result = pca.fit_transform(X_transformed)\n",
        "\n",
        "# Create a DataFrame with the PCA components\n",
        "pca_columns = [f'PCA_{i+1}' for i in range(pca_result.shape[1])]\n",
        "pca_df = pd.DataFrame(data=pca_result, columns=pca_columns)\n",
        "\n",
        "# Concatenate the PCA components with the original dataset\n",
        "dataset = pd.concat([dataset, pca_df], axis=1)\n",
        "\n",
        "# Display the updated dataset\n",
        "print(\"Updated Dataset Information after Dimensionality Reduction:\")\n",
        "print(dataset.info())\n",
        "\n"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "PCA can significantly reduce the computational burden, especially when dealing with a large number of features. By retaining the most important components, the dataset becomes more manageable for machine learning algorithms.\n",
        "\n",
        "In summary, PCA is chosen for its ability to reduce dimensionality while retaining most of the information in the dataset. It is a widely used technique for preprocessing data, especially when dealing with multicollinearity or high-dimensional datasets.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Split your data to train and test. Choose Splitting ratio wisely.\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "# Selecting  features (X) and target variable (y)\n",
        "X = dataset.drop('Response', axis=1)  # Features\n",
        "y = dataset['Response']  # Target variable\n",
        "\n",
        "# Split the data into training and testing sets (80-20 split ratio)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Display the shapes of the resulting sets\n",
        "print(\"Shape of X_train:\", X_train.shape)\n",
        "print(\"Shape of X_test:\", X_test.shape)\n",
        "print(\"Shape of y_train:\", y_train.shape)\n",
        "print(\"Shape of y_test:\", y_test.shape)\n"
      ],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The 80-20 ratio is a commonly used and reasonable choice for splitting data into training and testing sets. The majority of the data (80%) is used for training the model, allowing it to learn patterns and relationships from a large portion of the dataset. The remaining 20% is used for testing, enabling the evaluation of the model's performance on unseen data. This ratio strikes a balance between having enough data for training and having a sufficient amount for testing to assess generalization performance"
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# check for imbalance in data\n",
        "dataset['Response'].value_counts()"
      ],
      "metadata": {
        "id": "x0ifpOTcXrRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset is imbalanced because there is a significant difference in the number of instances between the two classes. Class 0 is the majority class, and Class 1 is the minority class. This imbalance can impact the performance of machine learning models, particularly for the minority class, and may require specific strategies such as resampling techniques or using appropriate evaluation metrics"
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset.columns"
      ],
      "metadata": {
        "id": "RPW7NPfGFmLj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The provided code snippet (dataset['Response'].value_counts()) checks and shows the class distribution in the 'Response' variable, indicating whether the dataset is imbalanced or not"
      ],
      "metadata": {
        "id": "IVno7WBbxWQB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "3 # ML Model - 1 Implementation\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "\n",
        "# Fit the Algorithm\n",
        "logistic_regression_model = LogisticRegression()\n",
        "logistic_regression_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_lr = logistic_regression_model.predict(X_test)\n",
        "\n"
      ],
      "metadata": {
        "id": "Wh-leGx6voIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "ArJBuiUVfxKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "import warnings\n",
        "from sklearn.exceptions import FitFailedWarning\n",
        "\n",
        "# Ignore FitFailedWarning and other warnings\n",
        "warnings.simplefilter(\"ignore\", category=FitFailedWarning)\n",
        "warnings.simplefilter(\"ignore\", category=UserWarning)\n",
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import roc_auc_score, roc_curve\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Define the parameter grid for Logistic Regression\n",
        "param_grid_lr = {'C': [0.001, 0.01, 0.1, 1, 10, 100], 'penalty': ['l1', 'l2']}\n",
        "grid_search_lr = GridSearchCV(logistic_regression_model, param_grid_lr, cv=5, scoring='accuracy')\n",
        "grid_search_lr.fit(X_train, y_train)\n",
        "\n",
        "# Get the best hyperparameters\n",
        "best_params_lr = grid_search_lr.best_params_\n",
        "\n",
        "# Visualizing ROC-AUC curve\n",
        "fpr_lr, tpr_lr, _ = roc_curve(y_test, grid_search_lr.predict_proba(X_test)[:, 1])\n",
        "roc_auc_lr = roc_auc_score(y_test, grid_search_lr.predict_proba(X_test)[:, 1])\n",
        "\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.plot(fpr_lr, tpr_lr, label=f'ROC curve (area = {roc_auc_lr:.2f})')\n",
        "plt.plot([0, 1], [0, 1], 'k--', label='Random')\n",
        "plt.title('ROC Curve for Logistic Regression (Hyperparameter Tuning)')\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "print(\"Logistic Regression Model Evaluation:\")\n",
        "print(f\"Best Hyperparameters: {best_params_lr}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AG3FEkyx3AN6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "\n",
        "# Evaluation metrics\n",
        "accuracy_lr = accuracy_score(y_test, y_pred_lr)\n",
        "conf_matrix_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "classification_rep_lr = classification_report(y_test, y_pred_lr)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_lr}\")\n",
        "print(\"Confusion Matrix:\")\n",
        "print(conf_matrix_lr)\n",
        "print(\"Classification Report:\")\n",
        "print(classification_rep_lr)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "QIaMrK-76k5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This technique systematically searches through a specified hyperparameter grid, evaluating the model's performance using cross-validation. It considers all possible combinations of hyperparameter values and identifies the combination that yields the best performance based on the specified scoring metric"
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model achieved an accuracy of 87.51% after hyperparameter tuning.\n",
        "The confusion matrix and classification report provide insights into the model's performance on different classes."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import recall_score, precision_score, f1_score, accuracy_score, roc_auc_score, roc_curve, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Step 1: RandomForestClassifier Implementation\n",
        "RF_model= RandomForestClassifier()\n",
        "RF_model= RF_model.fit(X_train, y_train)\n",
        "\n",
        "#Making prediction\n",
        "rf_prediction= RF_model.predict(X_test)\n",
        "rf_probability= RF_model.predict_proba(X_test)[:,1]\n"
      ],
      "metadata": {
        "id": "L0Fathn2u30c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation\n",
        "r_rf=  recall_score(y_test, rf_prediction)\n",
        "print(\"recall_score : \", r_rf)\n",
        "\n",
        "p_rf= precision_score(y_test, rf_prediction)\n",
        "print(\"precision_score :\",p_rf)\n",
        "\n",
        "f1_rf= f1_score(y_test, rf_prediction)\n",
        "print(\"f1_score :\", f1_rf)\n",
        "\n",
        "A_rf= accuracy_score(y_test, rf_prediction)\n",
        "print(\"accuracy_score :\",A_rf)\n",
        "\n",
        "acu_rf = roc_auc_score(rf_prediction, y_test)\n",
        "print(\"ROC_AUC Score:\",acu_rf)"
      ],
      "metadata": {
        "id": "q3iWHdbQC-xp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Visualizing Evaluation Metric Score Chart\n",
        "fpr, tpr, _ = roc_curve(y_test, rf_probability)\n",
        "\n",
        "plt.title('Random Forest ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr, tpr)\n",
        "plt.plot((0, 1), linestyle=\"--\", color='black')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "BJPcD6hiwFNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matrix= confusion_matrix(y_test,rf_prediction)\n",
        "print(matrix)\n",
        "sns.heatmap(matrix ,annot=True, fmt='g')"
      ],
      "metadata": {
        "id": "L1Qt-aZjC1Ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "print(classification_report(rf_prediction, y_test))"
      ],
      "metadata": {
        "id": "D7t8fCoTDHqv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After training the RandomForestClassifier, the model achieved the following metrics on the test set:\n",
        "\n",
        "Recall: 0.09\n",
        "Precision: 0.40\n",
        "F1-score: 0.15\n",
        "Accuracy: 86.95%\n",
        "ROC-AUC Score: 0.64\n",
        "The confusion matrix shows improvements in correctly predicting the negative class (0), but there is still room for improvement in predicting the positive class (1). The ROC curve visually represents the trade-off between true positive rate and false positive rate."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recall (Sensitivity): High recall is crucial when missing positive cases has a high cost. In fraud detection, it reduces financial losses by identifying most fraudulent transactions.\n",
        "\n",
        "Precision: High precision is important when the cost of false positives is high. In medical diagnosis, it ensures that predicted positive cases are likely to be correct, reducing unnecessary treatments and costs.\n",
        "\n",
        "F1-score: F1-score balances precision and recall, valuable in scenarios with class imbalance, like rare diseases, where it ensures accurate identification of rare cases.\n",
        "\n",
        "Accuracy: While measuring overall correctness, accuracy can be misleading in imbalanced datasets. In fraud detection, relying on accuracy alone might lead to overlooking fraudulent cases.\n",
        "\n",
        "ROC-AUC Score: ROC-AUC signifies the model's ability to discriminate between positive and negative instances. Higher ROC-AUC indicates better discrimination, crucial in scenarios like disease diagnosis.\n",
        "\n",
        "Understanding these metrics aligns the model's performance with business goals, considering the costs associated with false positives and false negatives in a specific context. Each metric provides a unique perspective on the model's performance relevant to different business scenarios."
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install xgboost\n"
      ],
      "metadata": {
        "id": "97o_4H5oMvN-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier\n"
      ],
      "metadata": {
        "id": "LHHq6FPBMvCi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: XGBoost Classifier Implementation\n",
        "XG_model = XGBClassifier()\n",
        "XG_model = XG_model.fit(X_train, y_train)\n",
        "\n",
        "# Making prediction\n",
        "XG_prediction = XG_model.predict(X_test)\n",
        "XG_probability = XG_model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "z_u5Vl86fYoN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Evaluate the XGBoost Model\n",
        "r_XG = recall_score(y_test, XG_prediction)\n",
        "print(\"Recall Score: \", r_XG)\n",
        "\n",
        "p_XG = precision_score(y_test, XG_prediction)\n",
        "print(\"Precision Score: \", p_XG)\n",
        "\n",
        "f1_XG = f1_score(y_test, XG_prediction)\n",
        "print(\"F1 Score: \", f1_XG)\n",
        "\n",
        "A_XG = accuracy_score(y_test, XG_prediction)\n",
        "print(\"Accuracy Score: \", A_XG)\n",
        "\n",
        "acu_XG = roc_auc_score(y_test, XG_prediction)\n",
        "print(\"ROC_AUC Score: \", acu_XG)"
      ],
      "metadata": {
        "id": "9bxPtVHJKbbv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing ROC curve\n",
        "fpr_XG, tpr_XG, _ = roc_curve(y_test, XG_probability)\n",
        "plt.title('XGBoost ROC curve')\n",
        "plt.xlabel(\"False Positive Rate\")\n",
        "plt.ylabel(\"True Positive Rate\")\n",
        "plt.plot(fpr_XG, tpr_XG)\n",
        "plt.plot((0, 1), linestyle=\"--\", color='black')\n",
        "plt.show()\n",
        "\n",
        "# Step 3: Generate and display the confusion matrix\n",
        "matrix_XG = confusion_matrix(y_test, XG_prediction)\n",
        "print(matrix_XG)\n",
        "\n",
        "# Visualize the confusion matrix using a heatmap\n",
        "sns.heatmap(matrix_XG, annot=True, fmt='g')\n",
        "plt.show()\n",
        "\n",
        "# Display classification report\n",
        "print(classification_report(XG_prediction, y_test))"
      ],
      "metadata": {
        "id": "I4QFIrFJKcMc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I have used the default hyperparameters provided by XGBoost in this implementation. XGBoost often performs well with its default settings, and for simplicity, I wanted to observe its initial performance before diving into hyperparameter tuning"
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to the default model, the XGBoost classifier has shown some improvement. The ROC-AUC score has increased from approximately 0.5 (random guessing) to 0.51, indicating a slight improvement in the model's ability to discriminate between positive and negative instances."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The XGBoost model has shown slight improvement compared to default settings:\n",
        "\n",
        "Recall Score: Low (0.023) - Identifies few positive cases.\n",
        "Precision Score: Moderate (0.437) - Positive predictions are often correct.\n",
        "F1 Score: Low (0.044) - Imbalanced precision and recall.\n",
        "Accuracy: 87.42%- Can be misleading in imbalanced datasets.\n",
        "ROC-AUC Score: Marginally above 0.5 - Slight improvement in discriminatory power.\n",
        "These metrics provide nuanced insights for business decisions, highlighting trade-offs between precision and recall in different scenarios."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        " I would choose the Logistic Regression model as the final prediction model because it achieved the highest accuracy among the three models, with an accuracy of 87.51%. Accuracy is a commonly used metric for classification models, and in this case, the Logistic Regression model demonstrated the best overall performance on the given dataset."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Explain the model which you have used and the feature importance using any model explainability tool?"
      ],
      "metadata": {
        "id": "HvGl1hHyA_VK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install shap\n"
      ],
      "metadata": {
        "id": "fmciuZc-XUJt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shap\n",
        "\n",
        "# Assuming 'logistic_regression_model' is your trained logistic regression model and 'X_test' is your test data\n",
        "explainer = shap.Explainer(logistic_regression_model.predict, X_train)\n",
        "shap_values = explainer.shap_values(X_test)\n"
      ],
      "metadata": {
        "id": "8brxHhTnXyF1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The logistic regression model was explained using SHAP (SHapley Additive exPlanations). SHAP values quantify the influence of each feature on model predictions. Positive SHAP values increase the predicted probability, while negative values decrease it. Features with higher absolute SHAP values have a greater impact. For instance, 'Previously_Insured' had a consistently high positive impact, indicating a positive influence on predicting interest in vehicle insurance. 'Age' had a consistently high negative impact, suggesting a negative influence. SHAP values provide a detailed and interpretable understanding of feature importance in the logistic regression model."
      ],
      "metadata": {
        "id": "YnvVTiIxBL-C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the File\n",
        "from joblib import dump\n",
        "\n",
        "# Assuming 'best_model' is the best-performing model\n",
        "best_model = logistic_regression_model  # Replace with your actual best-performing model\n",
        "\n",
        "# Save the model to a file\n",
        "dump(best_model, 'best_model.joblib')\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the necessary libraries\n",
        "from joblib import load\n",
        "import pandas as pd\n",
        "\n",
        "# Load the corrected model (make sure it doesn't include PCA components)\n",
        "loaded_model = load('corrected_best_model.joblib')  # Replace with the correct file name\n",
        "\n",
        "# Load your new, unseen data (replace 'your_data.csv' with your actual file path)\n",
        "X_unseen = pd.read_csv('/content/TRAIN-HEALTH INSURANCE CROSS SELL PREDICTION.csv')\n",
        "\n",
        "# Identify the features used during training (excluding PCA components)\n",
        "features_used_for_training = ['Age', 'Driving_License', 'Region_Code', 'Previously_Insured', 'Annual_Premium', 'Policy_Sales_Channel', 'Vintage', 'Gender']\n",
        "\n",
        "# Ensure that the features in features_used_for_training are present in X_unseen\n",
        "missing_features = set(features_used_for_training) - set(X_unseen.columns)\n",
        "if missing_features:\n",
        "    raise ValueError(f\"Missing features in X_unseen: {missing_features}\")\n",
        "\n",
        "# Make Predictions\n",
        "predictions = loaded_model.predict(X_unseen[features_used_for_training])\n",
        "\n",
        "# Sanity check\n",
        "print(predictions)\n"
      ],
      "metadata": {
        "id": "axNs_TOlF8q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "After conducting a comprehensive analysis of the dataset, it is evident that demographic factors play a significant role in predicting interest in vehicle insurance. The data revealed a gender imbalance, with more male customers than female customers, and highlighted the age group of 20 to 30 as exhibiting a higher interest in insurance. Notably, younger customers, particularly those below 30, displayed less inclination towards vehicle insurance. Vehicle characteristics also proved influential, with customers owning vehicles older than 2 years or those with damaged vehicles showing a greater likelihood of interest. Key variables impacting interest included age, Previously_Insured, and Annual_premium, as identified through the application of Mutual Information for Feature Selection.\n",
        "\n",
        "In the modeling phase, three algorithms—logistic regression, random forest classifier, and XGBoost—were employed to predict interest in vehicle insurance. The logistic regression model emerged as the most effective, achieving an accuracy of 87.51% after hyperparameter tuning. This model outperformed the others, as indicated by its higher accuracy and the insights gleaned from the confusion matrix and classification report. In contrast, the random forest classifier exhibited lower recall, precision, and F1-score, while XGBoost showed improved accuracy but fell short of surpassing the logistic regression model.\n",
        "\n",
        "Considering the overall performance metrics and accuracy, the logistic regression model was selected as the final prediction model. This decision is grounded in the understanding that accuracy is a pivotal metric for classification models, and in this specific context, the logistic regression model demonstrated superior performance on the given dataset.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}